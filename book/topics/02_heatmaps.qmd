# Heatmap Scaling {background-color="#e67e22"}

::: {.content-visible unless-format="revealjs"}
## Introduction

Heatmaps are ubiquitous in omics research for visualizing large-scale data matrices. However, one of the most common mistakes is using default scaling, which allows outliers to compress all meaningful variation into an indistinguishable range of colors. This chapter shows you how to properly handle scaling and outliers in heatmaps, and reveals a critical bug in many R heatmap functions.

### Learning Objectives

By the end of this chapter, you will:

- Understand how outliers compress color scales in heatmaps
- Learn three robust scaling approaches: MAD scaling, quantile capping, and log transformation
- Discover the hidden dendrogram scaling bug in base R heatmap functions
- Know why scaling matters for clustering analysis
- Be able to use `massageR::heat.clust()` for proper integrated scaling
- Choose appropriate color scales for different data types
:::

## The Outlier Problem

**Scenario**: Metabolomics data (log2-transformed)

- Most metabolites: 6 to 10 (log2 scale)
- 1 outlier metabolite: ~10 (2^10 = 1000x higher!)

::: {.fragment}
**What happens with default scaling?**

The extreme outlier compresses the color scale for all other values!

:::

## Visual Example: The Outlier Effect

```{r}
#| label: setup-heatmaps
#| echo: false
#| eval: true

library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(patchwork)
library(massageR)

# Define robust MAD scaling function (reusable)
scale_mad <- function(x) {
  (x - median(x, na.rm = TRUE)) / mad(x, na.rm = TRUE)
}

# Define quantile capping function (reusable)
cap_quantiles <- function(x, lower = 0.05, upper = 0.95) {
  q_lower <- quantile(x, lower, na.rm = TRUE)
  q_upper <- quantile(x, upper, na.rm = TRUE)
  pmin(pmax(x, q_lower), q_upper)
}
```

```{r}
#| label: heatmap-outlier-example
#| echo: false
#| eval: true

library(tibble)
library(dplyr)
library(tidyr)

# Simulate metabolomics data (positive only, with clustering)
set.seed(123)
# Create two groups of samples with different metabolite patterns
# Samples in rows, metabolites in columns (standard data format)
group1 <- matrix(rlnorm(50, meanlog = 2, sdlog = 0.8), nrow = 5, ncol = 10)
group2 <- matrix(rlnorm(50, meanlog = 6, sdlog = 0.8), nrow = 5, ncol = 10)

expr_data <- rbind(group1, group2) %>%
  as_tibble(.name_repair = ~paste0("Metabolite_", 1:10)) %>%
  mutate(Sample = c(paste0("Control", 1:5), paste0("Treatment", 1:5)), .before = 1)

# Add outliers to half the metabolites (5 out of 10)
# Each affected metabolite has 1-3 samples with extreme values
set.seed(456)
for (i in 1:5) {  # First 5 metabolites get outliers
  metab_col <- paste0("Metabolite_", i)
  normal_range <- max(expr_data[[metab_col]])

  # Randomly select 1-3 samples for this metabolite
  n_outliers <- sample(1:3, 1)
  outlier_samples <- sample(1:10, n_outliers)

  for (s in outlier_samples) {
    # Make it high (1.2-2x normal range)
    expr_data[s, metab_col] <- normal_range * runif(1, 2, 8)
  }
}

# Use magma scale for positive-only data (no meaningful center)
expr_mat_outlier <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

p <- pheatmap(expr_mat_outlier,
              main = "With outliers: All data compressed!",
              color = rev(viridis::magma(100)),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| label: heatmap-outlier-plot
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
::: {.fragment}
**Without Outlier Handling**

- Outliers dominate the color scale
- Most data compressed into narrow range
- Group differences invisible
- Patterns lost ðŸ˜±
:::
:::
:::



## Solution 1: Robust MAD Scaling and Cutoffs


::: {.columns}
::: {.column width="60%"}


```{r}
#| label: sd-cutoff
#| echo: true
#| eval: true

# Step 1: Robust scaling using MAD (Median Absolute Deviation)
expr_scaled <- expr_data %>%
  mutate(across(-Sample, scale_mad))

# Step 2: Identify which values will be capped
expr_mat_scaled <- expr_scaled %>% column_to_rownames("Sample") %>% as.matrix()
capped_cells <- (expr_mat_scaled < -3) | (expr_mat_scaled > 3)

# Step 3: Cap at Â±3 (meaningful after MAD scaling!)
expr_capped <- expr_scaled %>% mutate(across(-Sample, ~ pmin(pmax(.x, -3), 3)))

# Step 4: Create symmetric breaks centered at 0
max_abs <- max(abs(range(expr_capped[,-1])))
breaks  <- seq(-max_abs, max_abs, length.out = 101)
```




:::

::: {.column width="40%"}


```{r}
#| label: sd-cutoff-make-plot
#| echo: true
#| eval: true

# Create asterisk markers for capped values (in original order)
asterisk_matrix <- matrix("", nrow = nrow(capped_cells), ncol = ncol(capped_cells))
asterisk_matrix[capped_cells] <- "*"

# Create final plot with asterisk markers
# display_numbers uses the original data order, clustering is applied automatically
p <- pheatmap(expr_capped %>% column_to_rownames("Sample"),
              main = "MAD-scaled + capped at Â±3 (* = capped)",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks, scale = "none",
              display_numbers = asterisk_matrix,
              number_color = "black",
              fontsize_number = 14,
              silent = TRUE)
```


:::
:::


::: {.columns}
::: {.column width="60%"}


```{r}
#| label: sd-cutoff-plot
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4

p
```



:::
::: {.column width="40%"}


**Robust scaling approach**

- **Use MAD instead of SD** - not affected by outliers
- Center by median (robust)
- Scale by MAD (Median Absolute Deviation)
- Then cap at Â±3 MAD (~99% of normal data)
- Outliers now exceed threshold!
- Set `scale = "none"` (already scaled!)

:::
:::

## Solution 2: Range scaling and Quantile-Based cut-off


::: {.columns}
::: {.column width="60%"}


```{r}
#| label: quantile-cutoff
#| echo: true
#| eval: true

# Step 1: Identify values outside 5-95 percentiles PER COLUMN
expr_mat_raw <- expr_data %>% column_to_rownames("Sample") %>% as.matrix()
capped_cells_q <- apply(expr_mat_raw, 2, function(x) {
  q_lower <- quantile(x, 0.05, na.rm = TRUE)
  q_upper <- quantile(x, 0.95, na.rm = TRUE)
  (x < q_lower) | (x > q_upper)
})

# Step 2: Cap at 5th and 95th percentiles PER COLUMN (metabolite)
expr_capped <- expr_data %>%
  mutate(across(-Sample, ~ cap_quantiles(.x, lower = 0.05, upper = 0.95)))

# Step 3: Range scaling (min-max normalization to [0,1])
expr_quantile <- expr_capped %>% mutate(across(-Sample, ~ (.x - min(.x)) / (max(.x) - min(.x))))
```




:::

::: {.column width="40%"}


```{r}
#| label: quantile-cutoff-make-plot
#| echo: true
#| eval: true

# Create asterisk markers for capped values (in original order)
asterisk_matrix_q <- matrix("", nrow = nrow(capped_cells_q), ncol = ncol(capped_cells_q))
asterisk_matrix_q[capped_cells_q] <- "*"

# Create final plot with asterisk markers
p <- pheatmap(expr_quantile %>% column_to_rownames("Sample"),
              main = "Capped at 5-95 percentiles + range-scaled (* = capped)",
              color = rev(viridis::magma(100)),
              display_numbers = asterisk_matrix_q,
              number_color = "white",
              fontsize_number = 14,
              silent = TRUE)
```


:::
:::



::: {.columns}
::: {.column width="60%"}


```{r}
#| label: quantile-cutoff-plot
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4

p
```



:::
::: {.column width="40%"}


**Quantile capping + range scaling**

- Cap first to remove outliers **per metabolite**
- Then range scale to use full [0,1] color scale
- More robust to outliers than variance scaling
- Good for non-normal data
- Common quantiles: 5-95% or 2-98%

:::
:::


## Solution 3: Log Transformation

**For positive values only** (e.g., counts, intensities)

```{r}
#| label: log-transform
#| echo: true
#| eval: true

# Log transform BEFORE plotting (metabolomics data is positive-only)
expr_log_sol4 <- expr_data %>%
  mutate(across(-Sample, ~ log2(.x + 1)))  # +1 to handle zeros

p <- pheatmap(expr_log_sol4 %>% column_to_rownames("Sample"),
              main = "Log2 transformed metabolite intensities",
              color = rev(viridis::magma(100)),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| label: log-transform-plot
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
**For count/intensity data**

- Compresses wide ranges
- Add +1 to handle zeros
- Common for RNA-seq, proteomics
- Use log2, log10, or ln
:::
:::



## The Dendrogram Scaling Trap

::: {.callout-warning}
## Hidden Technical Issue

**Critical R bug**: Functions like `heatmap()`, `heatmap.2()`, and `heatplot()` have a dangerous inconsistency:

- The `scale` parameter affects **color visualization**
- But **NOT** dendrogram calculation!

**Result**: Dendrograms cluster on unscaled data while colors show scaled data!

\

P.S: `pheatmap()` seems to apply scaling and cropping before clustering!
:::





## Why Scaling Matters for Clustering

**The Problem: High-variance features dominate correlations**

Without scaling, features with large values dominate sample correlations!

```{r}
#| label: scaling-demo
#| echo: false
#| eval: true
#| fig-width: 12
#| fig-height: 5

library(corrplot)

# Use our metabolomics data (samples in rows, metabolites in columns)
expr_mat <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

# Correlation plots: samples correlated across metabolites
par(mfrow = c(1, 2))

# WITHOUT scaling: appears highly correlated
corrplot(cor(t(expr_mat)), method = "color",
         title = "Unscaled: Everything looks correlated!",
         mar = c(0,0,2,0), tl.cex = 0.8)

# WITH scaling: true correlation structure revealed
expr_scaled <- scale(expr_mat)
corrplot(cor(t(expr_scaled)), method = "color",
         title = "Scaled: True sample relationships",
         mar = c(0,0,2,0), tl.cex = 0.8)
```


## Why Scaling Matters for Clustering (2)

```{r}
#| label: scatter-demo
#| echo: false
#| eval: true
#| fig-width: 12
#| fig-height: 5

library(ggpubr)
library(patchwork)

# Prepare data for ggplot
scatter_data_unscaled <- data.frame(
  Treatment5 = expr_mat["Treatment5",],
  Control4 = expr_mat["Control4",]
)

scatter_data_scaled <- data.frame(
  Treatment5 = expr_scaled["Treatment5",],
  Control4 = expr_scaled["Control4",]
)

# Unscaled: correlation driven by high-variance metabolites
p1 <- ggscatter(scatter_data_unscaled, x = "Treatment5", y = "Control4",
                add = "reg.line", conf.int = TRUE,
                cor.coef = TRUE, cor.method = "pearson",
                title = "Unscaled samples")

# Scaled: true relationship visible
p2 <- ggscatter(scatter_data_scaled, x = "Treatment5", y = "Control4",
                add = "reg.line", conf.int = TRUE,
                cor.coef = TRUE, cor.method = "pearson",
                title = "Scaled samples",
                xlab = "Treatment5 (scaled)", ylab = "Control4 (scaled)")

p1 + p2
```

::: {.fragment}
**Key point**: Without scaling, high-variance metabolites completely dominate the correlation calculation between samples!

Scaling ensures all metabolites contribute equally to sample clustering.
:::


## Using massageR::heat.clust

::: {.callout-tip}
## Better Approach: heat.clust

The `massageR` package provides `heat.clust()` which handles scaling and dendrogram calculation correctly in one step!

**Key advantages:**

- Scales data and calculates dendrograms together
- Controls exactly where limits are applied (data and/or dendrograms)
- Returns pre-computed dendrograms
- Works seamlessly with pheatmap
:::

## heat.clust with pheatmap

::: {.columns}
::: {.column width="60%"}


```{r}
#| label: heat-clust-pheatmap
#| echo: true
#| eval: true

library(massageR)

# Convert tibble to matrix for heat.clust
expr_matrix <- expr_data %>% column_to_rownames("Sample") %>% as.matrix()

# Use heat.clust with robust MAD scaling
z <- heat.clust(expr_matrix,
                scaledim = "column",           # Scale by column
                zlim = c(-3, 3),               # Cap at Â±3 MAD
                zlim_select = c("dend", "outdata"),  # Apply to both
                reorder = c(),                 # Reorder dendrograms off for consistency
                distfun = function(x) dist(x),
                hclustfun = function(x) hclust(x, method = "complete"),
                scalefun = scale_mad)          # Use MAD scaling instead of default

max_abs <- max(abs(range(z$data)))
breaks  <- seq(-max_abs, max_abs, length.out = 101)
```


:::

::: {.column width="40%"}


```{r}
#| label: heat-clust-pheatmap-make
#| echo: true
#| eval: true

# Use with pheatmap
p <- pheatmap(z$data,
              cluster_rows = as.hclust(z$Rowv),
              cluster_cols = as.hclust(z$Colv),
              scale = "none",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks,
              main = "heat.clust + pheatmap: Properly scaled!",
              silent = TRUE)
```

:::
:::





::: {.columns}
::: {.column width="60%"}

```{r}
#| label: heat-clust-plot
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 3.5

p
```

:::
::: {.column width="40%"}


**One-step workflow**

- Scales data automatically
- Calculates dendrograms on scaled data
- Caps at specified zlim
- Returns everything needed for pheatmap
- Ensures consistency throughout

:::
:::

## Comparison: Before and After

```{r}
#| label: heatmap-comparison
#| echo: false
#| eval: true
#| fig-width: 14
#| fig-height: 6

# Side-by-side comparison
library(gridExtra)

# Before: with outliers (from "Visual Example: The Outlier Effect")
expr_mat_outlier_comp <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

p1 <- pheatmap(expr_mat_outlier_comp,
               main = "With outliers: All data compressed!",
               color = rev(viridis::magma(100)),
               silent = TRUE)

# After: MAD-scaled + capped (from "Solution 1: Robust MAD Scaling")
expr_scaled_comp <- expr_data %>%
  mutate(across(-Sample, scale_mad))
expr_mat_scaled_comp <- expr_scaled_comp %>% column_to_rownames("Sample") %>% as.matrix()
capped_cells_comp <- (expr_mat_scaled_comp < -3) | (expr_mat_scaled_comp > 3)
expr_capped_comp <- expr_scaled_comp %>% mutate(across(-Sample, ~ pmin(pmax(.x, -3), 3)))
max_abs_comp <- max(abs(range(expr_capped_comp[,-1])))
breaks_comp <- seq(-max_abs_comp, max_abs_comp, length.out = 101)

# Create asterisk markers for capped values (in original order)
asterisk_matrix_comp <- matrix("", nrow = nrow(capped_cells_comp), ncol = ncol(capped_cells_comp))
asterisk_matrix_comp[capped_cells_comp] <- "*"

# Final plot with asterisk markers
p2 <- pheatmap(expr_capped_comp %>% column_to_rownames("Sample"),
               main = "MAD-scaled + capped at Â±3 (* = capped)",
               color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
               breaks = breaks_comp,
               display_numbers = asterisk_matrix_comp,
               number_color = "black",
               fontsize_number = 14,
               scale = "none",
               silent = TRUE)

grid.arrange(p1[[4]], p2[[4]], ncol = 2)
```

## Best Practices & Recommendations

::: {.callout-tip}
## Workflow

1. **Inspect data distribution** before making heatmap
2. **Consider log transformation**
3. **Scale data BEFORE** passing to heatmap function
   - **Use MAD (robust)** if data has outliers: `(x - median(x)) / mad(x)`
   - Use SD if data is clean: `scale(x)`
4. Cap extremes
   - **Cap at Â±3 MAD** for robust scaling with outliers
   - **Cap using quantiles** (5-95%) if using range scaling
5. **Calculate dendrograms** on the same scaled and capped data
6. **Consider `massageR::heat.clust()`** for automatic proper scaling workflow
7. **Use appropriate palette**:
   - Often centering data highlights contrasts
   - Diverging color scale for data that has been centered (red-white-blue)
   - Sequential color scale for one-directional data (viridis, magma)

:::



::: {.callout-warning}
## When NOT to Cap

- If outliers are **biologically meaningful** (rare events)
- Small datasets where each value matters
- When you want to highlight extreme values

:::

::: {.content-visible unless-format="revealjs"}
## Summary

:::{.callout-tip}
## Key Takeaways

1. **Outliers compress color scales** - default scaling makes all non-outlier data invisible
2. **Use robust MAD scaling** - `(x - median(x)) / mad(x)` is not affected by outliers
3. **Cap at Â±3 MAD** - retains ~99% of normal data while handling extremes
4. **Alternative: quantile capping** - cap at 5-95 percentiles before range scaling
5. **Log transform positive data** - metabolomics, RNA-seq, proteomics intensities
6. **Beware the dendrogram bug** - base R heatmap functions don't scale before clustering!
7. **Use `massageR::heat.clust()`** - handles scaling and dendrograms correctly in one step
8. **Match color scales to data**:
   - Diverging (RdBu) for centered data
   - Sequential (magma/viridis) for positive-only data
:::

## Exercises

:::{.callout-note}
## Try It Yourself

1. Create a heatmap with simulated data containing outliers (use `rnorm()` plus a few extreme values)
2. Compare three approaches:
   - Default scaling with `pheatmap(..., scale = "row")`
   - MAD scaling with `scale_mad()` function and capping at Â±3
   - Quantile capping at 5-95 percentiles
3. Check if your dendrograms change between methods
4. Try `massageR::heat.clust()` and verify it produces consistent results
:::

## Further Reading

- [massageR package documentation](https://github.com/stanstrup/massageR) - for `heat.clust()` function
- [Why you should use MAD over SD](https://en.wikipedia.org/wiki/Median_absolute_deviation) - robust statistics
- [ComplexHeatmap book](https://jokergoo.github.io/ComplexHeatmap-reference/book/) - advanced heatmap customization
- Wilkinson & Friendly (2009). "The History of the Cluster Heat Map". *The American Statistician* - origins and best practices
:::
