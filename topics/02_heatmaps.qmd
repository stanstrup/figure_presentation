# Heatmap Scaling {background-color="#e67e22"}

## The Outlier Problem

**Scenario**: Metabolomics data (log2-transformed)

- Most metabolites: 6 to 10 (log2 scale)
- 1 outlier metabolite: ~10 (2^10 = 1000x higher!)

::: {.fragment}
**What happens with default scaling?**

The extreme outlier compresses the color scale for all other values!

:::

## Visual Example: The Outlier Effect

```{r}
#| label: setup-heatmaps
#| echo: false
#| eval: true

library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(patchwork)
library(massageR)
```

```{r}
#| label: heatmap-outlier-example
#| echo: false
#| eval: true

library(tibble)
library(dplyr)
library(tidyr)

# Simulate metabolomics data (positive only, with clustering)
set.seed(123)
# Create two groups of samples with different metabolite patterns
# Samples in rows, metabolites in columns (standard data format)
group1 <- matrix(rlnorm(50, meanlog = 2, sdlog = 0.8), nrow = 5, ncol = 10)
group2 <- matrix(rlnorm(50, meanlog = 6, sdlog = 0.8), nrow = 5, ncol = 10)

expr_data <- rbind(group1, group2) %>%
  as_tibble(.name_repair = ~paste0("Metabolite_", 1:10)) %>%
  mutate(Sample = c(paste0("Control", 1:5), paste0("Treatment", 1:5)), .before = 1)

# Add outliers to half the metabolites (5 out of 10)
# Each affected metabolite has 1-3 samples with extreme values
set.seed(456)
for (i in 1:5) {  # First 5 metabolites get outliers
  metab_col <- paste0("Metabolite_", i)
  normal_range <- max(expr_data[[metab_col]])

  # Randomly select 1-3 samples for this metabolite
  n_outliers <- sample(1:3, 1)
  outlier_samples <- sample(1:10, n_outliers)

  for (s in outlier_samples) {
    # Randomly make it very high (2-4x) or very low (0.25-0.5x)
      expr_data[s, metab_col] <- normal_range * runif(1, 1.2, 2)
  }
}

# Use viridis scale for positive-only data (no meaningful center)
expr_mat_outlier <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

p <- pheatmap(expr_mat_outlier,
              main = "With outliers: All data compressed!",
              color = rev(viridis::magma(100)),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
::: {.fragment}
**Without Outlier Handling**

- Scale: -6 to +6
- ~99.7% of data: -3 to +3 (Â±3 SD)
- Uses only half the color range
- Real patterns invisible ðŸ˜±
:::
:::
:::



## Solution 1: Standard Deviation Cutoffs


::: {.columns}
::: {.column width="65%"}


```{r}
#| label: sd-cutoff
#| echo: true
#| eval: true

# Step 1: Scale variables to unit variance (mean=0, sd=1)
expr_scaled <- expr_data %>% mutate(across(-Sample, ~ scale(.x)[,1]))

# Step 2: Cap at Â±3 (only meaningful after scaling!)
expr_capped <- expr_scaled %>% mutate(across(-Sample, ~ pmin(pmax(.x, -3), 3)))

# Step 3: Create symmetric breaks centered at 0
max_abs <- max(abs(range(expr_capped[,-1])))
breaks  <- seq(-max_abs, max_abs, length.out = 101)

p <- pheatmap(expr_capped %>% column_to_rownames("Sample"),
              main = "Scaled + capped at Â±3",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks, scale = "none", silent = TRUE)
```


```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4

p
```

:::

::: {.column width="35%"}

**Most common approach**

- **Scale FIRST** to unit variance
- Then cap at Â±2 or Â±3
- Â±2 captures ~95.4% of data
- Â±3 captures ~99.7% of data
- Uses full color range
- Set `scale = "none"` (already scaled!)

:::
:::




## Solution 2: Quantile-Based

```{r}
#| label: quantile-cutoff
#| echo: true
#| eval: true

# Step 1: Cap at 5th and 95th percentiles PER COLUMN (metabolite)
expr_capped <- expr_data %>%
  mutate(across(-Sample, ~ {
    lower <- quantile(.x, 0.05, na.rm = TRUE)
    upper <- quantile(.x, 0.95, na.rm = TRUE)
    pmin(pmax(.x, lower), upper)
  }))

# Step 2: Range scaling (min-max normalization to [0,1])
expr_quantile <- expr_capped %>% mutate(across(-Sample, ~ (.x - min(.x)) / (max(.x) - min(.x))))

p <- pheatmap(expr_quantile %>% column_to_rownames("Sample"),
              main = "Capped at 5-95 percentiles + range-scaled",
              color = rev(viridis::magma(100)), silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
**Quantile capping + range scaling**

- Cap first to remove outliers **per metabolite**
- Then range scale to use full [0,1] color scale
- More robust to outliers than variance scaling
- Good for non-normal data
- Common quantiles: 5-95% or 2-98%
:::
:::

## Solution 3: Manual Breaks

```{r}
#| label: manual-breaks
#| echo: true
#| eval: true

# Step 1: Scale to unit variance first by row
expr_scaled <- expr_data %>%
  mutate(across(-Sample, ~ scale(.x)[,1]))

# Step 2: Define your own color breaks
breaks <- seq(-3, 3, length.out = 101)

p <- pheatmap(expr_scaled %>% column_to_rownames("Sample"),
              breaks = breaks,
              main = "Scaled + custom breaks: -3 to +3",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              scale = "none", silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
**Maximum control**

- **Scale FIRST** to unit variance
- Then define exact breaks
- Values outside range â†’ extremes
- Good when you know your data
- Can combine with capping
:::
:::

## Solution 4: Log Transformation

**For positive values only** (e.g., counts, intensities)

```{r}
#| label: log-transform
#| echo: true
#| eval: true

# Log transform BEFORE plotting (metabolomics data is positive-only)
expr_log_sol4 <- expr_data %>%
  mutate(across(-Sample, ~ log2(.x + 1)))  # +1 to handle zeros

p <- pheatmap(expr_log_sol4 %>% column_to_rownames("Sample"),
              main = "Log2 transformed metabolite intensities",
              color = rev(viridis::magma(100)),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
**For count/intensity data**

- Compresses wide ranges
- Add +1 to handle zeros
- Common for RNA-seq, proteomics
- Use log2, log10, or ln
:::
:::



## The Dendrogram Scaling Trap

::: {.callout-warning}
## Hidden Technical Issue

**Critical R bug**: Functions like `heatmap()`, `heatmap.2()`, and `heatplot()` have a dangerous inconsistency:

- The `scale` parameter affects **color visualization**
- But **NOT** dendrogram calculation!

**Result**: Dendrograms cluster on unscaled data while colors show scaled data!

\

P.S: `pheatmap()` seems to apply scaling and cropping before clustering!
:::





## Why Scaling Matters for Clustering

**The Problem: High-variance features dominate correlations**

Without scaling, features with large values dominate sample correlations!

```{r}
#| label: scaling-demo
#| echo: false
#| eval: true
#| fig-width: 12
#| fig-height: 5

library(corrplot)

# Use our metabolomics data (samples in rows, metabolites in columns)
expr_mat <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

# Correlation plots: samples correlated across metabolites
par(mfrow = c(1, 2))

# WITHOUT scaling: appears highly correlated
corrplot(cor(t(expr_mat)), method = "color",
         title = "Unscaled: Everything looks correlated!",
         mar = c(0,0,2,0), tl.cex = 0.8)

# WITH scaling: true correlation structure revealed
expr_scaled <- scale(expr_mat)
corrplot(cor(t(expr_scaled)), method = "color",
         title = "Scaled: True sample relationships",
         mar = c(0,0,2,0), tl.cex = 0.8)
```

```{r}
#| label: scatter-demo
#| echo: false
#| eval: true
#| fig-width: 12
#| fig-height: 5

library(ggpubr)
library(patchwork)

# Prepare data for ggplot
scatter_data_unscaled <- data.frame(
  Treatment5 = expr_mat["Treatment5",],
  Control4 = expr_mat["Control4",]
)

scatter_data_scaled <- data.frame(
  Treatment5 = expr_scaled["Treatment5",],
  Control4 = expr_scaled["Control4",]
)

# Unscaled: correlation driven by high-variance metabolites
p1 <- ggscatter(scatter_data_unscaled, x = "Treatment5", y = "Control4",
                add = "reg.line", conf.int = TRUE,
                cor.coef = TRUE, cor.method = "pearson",
                title = "Unscaled samples")

# Scaled: true relationship visible
p2 <- ggscatter(scatter_data_scaled, x = "Treatment5", y = "Control4",
                add = "reg.line", conf.int = TRUE,
                cor.coef = TRUE, cor.method = "pearson",
                title = "Scaled samples",
                xlab = "Treatment5 (scaled)", ylab = "Control4 (scaled)")

p1 + p2
```

::: {.fragment}
**Key point**: Without scaling, high-variance metabolites completely dominate the correlation calculation between samples!

Scaling ensures all metabolites contribute equally to sample clustering.
:::

## Proper Heatmap Workflow

::: {.callout-important}
## The Right Approach

1. **Scale your data FIRST** (before creating heatmap)
2. **Calculate dendrograms on scaled data**
3. **Pass pre-calculated dendrograms to heatmap function**
4. **Set `scale = "none"`** in heatmap call


:::

## Using massageR::heat.clust

::: {.callout-tip}
## Better Approach: heat.clust

The `massageR` package provides `heat.clust()` which handles scaling and dendrogram calculation correctly in one step!

**Key advantages:**

- Scales data and calculates dendrograms together
- Controls exactly where limits are applied (data and/or dendrograms)
- Returns pre-computed dendrograms
- Works seamlessly with pheatmap
:::

## heat.clust with pheatmap

```{r}
#| label: heat-clust-pheatmap
#| echo: true
#| eval: true

library(massageR)

# Convert tibble to matrix for heat.clust
expr_matrix <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

# Use heat.clust to scale and cluster
z <- heat.clust(expr_matrix,
                scaledim = "column",           # Scale by column
                zlim = c(-3, 3),            # Cap at Â±3
                zlim_select = c("dend", "outdata"),  # Apply to both
                reorder = c(),        # Reorder dendrograms
                distfun = function(x) dist(x),
                hclustfun = function(x) hclust(x, method = "complete"),
                scalefun = scale)

max_abs <- max(abs(range(z$data)))
breaks  <- seq(-max_abs, max_abs, length.out = 101)

# Extract dendrograms and convert to hclust objects
row_dend <- as.hclust(z$Rowv)
col_dend <- as.hclust(z$Colv)

# Use with pheatmap
p <- pheatmap(z$data,
              cluster_rows = row_dend,
              cluster_cols = col_dend,
              scale = "none",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks,
              main = "heat.clust + pheatmap: Properly scaled!",
              silent = TRUE)
```

::: {.columns}
::: {.column width="40%"}
**One-step workflow**

- Scales data automatically
- Calculates dendrograms on scaled data
- Caps at specified zlim
- Returns everything needed for pheatmap
- Ensures consistency throughout
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
p
```
:::
:::

## Complete Example: Proper Scaling

```{r}
#| label: proper-scaling-example
#| echo: true
#| eval: true

# Step 1: Scale by row (metabolite)
data_scaled <- expr_data %>%
  mutate(across(-Sample, ~ scale(.x)[,1]))

# Step 2: Cap extremes at Â±2.5
data_capped <- data_scaled %>%
  mutate(across(-Sample, ~ pmin(pmax(.x, -2.5), 2.5)))

# Step 3: Calculate dendrograms on scaled data
data_mat <- data_capped %>% column_to_rownames("Sample") %>% as.matrix()
row_dend <- hclust(dist(data_mat))
col_dend <- hclust(dist(t(data_mat)))

# Step 4: Plot with consistent scaling
p <- pheatmap(data_mat,
              cluster_rows = row_dend,
              cluster_cols = col_dend,
              scale = "none",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = seq(-2.5, 2.5, length.out = 101),
              main = "Properly scaled: dendrograms match colors!",
              silent = TRUE)
```

::: {.columns}
::: {.column width="40%"}
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
p
```
:::
:::

## Diverging Scales for Centered Data

```{r}
#| label: diverging-scale
#| echo: true
#| eval: true
#| fig-width: 10
#| fig-height: 5

# When zero is meaningful (fold-change, z-scores, etc.)
# Use data_mat from previous chunk (already scaled and capped)
pheatmap(data_mat,
         color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
         breaks = seq(-2.5, 2.5, length.out = 101),
         main = "Diverging scale: zero = white")

# Zero = white, negative = blue, positive = red
```

## Comparison: Before and After

```{r}
#| label: heatmap-comparison
#| echo: false
#| eval: true
#| fig-width: 14
#| fig-height: 6

# Side-by-side comparison
library(gridExtra)

# Before: with outliers (from "Visual Example: The Outlier Effect")
expr_mat_outlier_comp <- expr_data %>%
  column_to_rownames("Sample") %>%
  as.matrix()

p1 <- pheatmap(expr_mat_outlier_comp,
               main = "With outliers: All data compressed!",
               color = rev(viridis::magma(100)),
               silent = TRUE)

# After: scaled + capped (from "Solution 1: Standard Deviation Cutoffs")
expr_scaled_comp <- expr_data %>% mutate(across(-Sample, ~ scale(.x)[,1]))
expr_capped_comp <- expr_scaled_comp %>% mutate(across(-Sample, ~ pmin(pmax(.x, -3), 3)))
max_abs_comp <- max(abs(range(expr_capped_comp[,-1])))
breaks_comp <- seq(-max_abs_comp, max_abs_comp, length.out = 101)

p2 <- pheatmap(expr_capped_comp %>% column_to_rownames("Sample"),
               main = "Scaled + capped at Â±3",
               color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
               breaks = breaks_comp,
               scale = "none",
               silent = TRUE)

grid.arrange(p1[[4]], p2[[4]], ncol = 2)
```

## Best Practices & Recommendations

::: {.callout-tip}
## Workflow

1. **Inspect data distribution** before making heatmap
2. **Consider log transformation**
3. **Scale data BEFORE** passing to heatmap function
4. Cap extremes
  - **Cap at 2-3 SD** for large datasets with outliers, if using unit variance scaling
  - **Cap using quantiles** (5-95%) if using range scaling
5. **Calculate dendrograms** on the same scaled and capped data
6. **Consider `massageR::heat.clust()`** for automatic proper scaling workflow
7. **Use appropriate palette**:
   - Often centering data highlights contrasts
   - Diverging color scale for data that has been centered (red-white-blue)
   - Sequential color scale for one-directional data (viridis, magma)

:::



::: {.callout-warning}
## When NOT to Cap

- If outliers are **biologically meaningful** (rare events)
- Small datasets where each value matters
- When you want to highlight extreme values

:::
