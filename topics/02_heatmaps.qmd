# Heatmap Scaling {background-color="#e67e22"}

## The Outlier Problem

**Scenario**: Metabolomics data (log2-transformed)

- Most metabolites: 6 to 10 (log2 scale)
- 1 outlier metabolite: ~10 (2^10 = 1000x higher!)

::: {.fragment}
**What happens with default scaling?**

The extreme outlier compresses the color scale for all other values!

:::

## Visual Example: The Outlier Effect

```{r}
#| label: setup-heatmaps
#| echo: false
#| eval: true

library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(patchwork)
library(massageR)
```

```{r}
#| label: heatmap-outlier-example
#| echo: false
#| eval: true

library(tibble)
library(dplyr)
library(tidyr)

# Simulate metabolomics data (positive only, with clustering)
set.seed(123)
# Create two groups of samples with different metabolite patterns
group1 <- matrix(rlnorm(50, meanlog = 2, sdlog = 0.8), nrow = 10, ncol = 5)
group2 <- matrix(rlnorm(50, meanlog = 2.5, sdlog = 0.8), nrow = 10, ncol = 5)

expr_data <- cbind(group1, group2) %>%
  as_tibble(.name_repair = ~c(paste0("Control", 1:5), paste0("Treatment", 1:5))) %>%
  mutate(Metabolite = paste0("Metabolite_", 1:10), .before = 1)

expr_data[5, "Treatment3"] <- 1000  # One extreme outlier

# Log-transform for visualization (metabolomics data is often log-transformed)
expr_log <- expr_data %>%
  mutate(across(-Metabolite, ~ log2(.x)))

# Use divergent ColorBrewer scale centered at mean
# RdBu = Red-Blue divergent scale (reversed so blue is high)
expr_mat_outlier <- expr_log %>% column_to_rownames("Metabolite")
data_center <- mean(as.matrix(expr_mat_outlier), na.rm = TRUE)
max_diff <- max(abs(as.matrix(expr_mat_outlier) - data_center))
breaks <- seq(data_center - max_diff, data_center + max_diff, length.out = 101)

p <- pheatmap(expr_mat_outlier,
              main = "With outlier: All data compressed!",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks,
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
p
```
:::

::: {.column width="40%"}
::: {.fragment}
**Without Outlier Handling**

- Scale: -6 to +6
- ~99.7% of data: -3 to +3 (Â±3 SD)
- Uses only half the color range
- Real patterns invisible ðŸ˜±
:::
:::
:::



## Solution 1: Standard Deviation Cutoffs


::: {.columns}
::: {.column width="65%"}


```{r}
#| label: sd-cutoff
#| echo: true
#| eval: true

# Step 1: Scale variables to unit variance (mean=0, sd=1)
expr_scaled <- expr_data %>% mutate(across(-Metabolite, ~ scale(.x)[,1]))

# Step 2: Cap at Â±3 (only meaningful after scaling!)
expr_capped <- expr_scaled %>% mutate(across(-Metabolite, ~ pmin(pmax(.x, -3), 3)))

# Step 3: Create symmetric breaks centered at 0
max_abs <- max(abs(range(expr_capped[,-1])))
breaks  <- seq(-max_abs, max_abs, length.out = 101)

p <- pheatmap(expr_capped %>% column_to_rownames("Metabolite"),
              main = "Scaled + capped at Â±3",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              breaks = breaks, scale = "none", silent = TRUE)
```


```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4

p
```

:::

::: {.column width="35%"}

**Most common approach**

- **Scale FIRST** to unit variance
- Then cap at Â±2 or Â±3
- Â±2 captures ~95.4% of data
- Â±3 captures ~99.7% of data
- Uses full color range
- Set `scale = "none"` (already scaled!)

:::
:::




## Solution 2: Quantile-Based

```{r}
#| label: quantile-cutoff
#| echo: true
#| eval: true

# Cap at 5th and 95th percentiles PER COLUMN (sample)
# Important: columns may be on different scales!
expr_quantile <- expr_data %>%
  mutate(across(-Metabolite, ~ {
    lower <- quantile(.x, 0.05, na.rm = TRUE)
    upper <- quantile(.x, 0.95, na.rm = TRUE)
    pmin(pmax(.x, lower), upper)
  }))

p <- pheatmap(expr_quantile %>% column_to_rownames("Metabolite"),
              main = "Values capped at 5-95 percentiles (per sample)",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
p
```
:::

::: {.column width="40%"}
**More robust approach**

- Uses percentiles **per sample**
- Handles different scales across samples
- Not affected by extreme outliers
- Good for non-normal data
- Common: 5-95% or 2-98%
:::
:::

## Solution 3: Manual Breaks

```{r}
#| label: manual-breaks
#| echo: true
#| eval: true

# Step 1: Scale to unit variance first by row
expr_scaled <- expr_data %>%
  mutate(across(-Metabolite, ~ scale(.x)[,1]))

# Step 2: Define your own color breaks
breaks <- seq(-3, 3, length.out = 101)

p <- pheatmap(expr_scaled %>% column_to_rownames("Metabolite"),
              breaks = breaks,
              main = "Scaled + custom breaks: -3 to +3",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              scale = "none",  # Already scaled!
              silent = TRUE)

# Values outside range automatically assigned to extremes
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
p
```
:::

::: {.column width="40%"}
**Maximum control**

- **Scale FIRST** to unit variance
- Then define exact breaks
- Values outside range â†’ extremes
- Good when you know your data
- Can combine with capping
:::
:::

## Solution 4: Log Transformation

**For positive values only** (e.g., counts, intensities)

```{r}
#| label: log-transform
#| echo: true
#| eval: true

# Create positive data (e.g., count data)
set.seed(123)
count_data <- matrix(rpois(100, lambda = 50), nrow = 10, ncol = 10) %>%
  as_tibble(.name_repair = ~paste0("Sample", 1:10)) %>%
  mutate(Gene = paste0("Metabolite", 1:10), .before = 1)

count_data[5, "Sample5"] <- 5000  # Extreme count

# Log transform BEFORE plotting
count_log <- count_data %>%
  mutate(across(-Metabolite, ~ log10(.x + 1)))  # +1 to handle zeros

p <- pheatmap(count_log %>% column_to_rownames("Metabolite"),
              main = "Log10 transformed counts",
              color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
              silent = TRUE)
```

::: {.columns}
::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
p
```
:::

::: {.column width="40%"}
**For count/intensity data**

- Compresses wide ranges
- Add +1 to handle zeros
- Common for RNA-seq, proteomics
- Use log2, log10, or ln
:::
:::



## The Dendrogram Scaling Trap

::: {.callout-warning}
## Hidden Technical Issue

**Critical R bug**: Functions like `heatmap()`, `heatmap.2()`, and `heatplot()` have a dangerous inconsistency:

- The `scale` parameter affects **color visualization**
- But **NOT** dendrogram calculation!

**Result**: Dendrograms cluster on unscaled data while colors show scaled data!
:::





## Why Scaling Matters for Clustering

**The Problem: High-variance features dominate distance**

Without scaling, features with large values dominate sample similarity!

```{r}
#| label: scaling-demo
#| echo: true
#| eval: true
#| fig-width: 12
#| fig-height: 5

set.seed(42)

# Create sample clustering example (metabolites Ã— samples)
# Gene 1: small variation (0-1 range)
# Gene 2: HUGE variation (0-1000 range) - dominates if not scaled!
metabolite_data <- data.frame(
  Sample1 = c(0.5, 100),
  Sample2 = c(0.6, 150),
  Sample3 = c(0.55, 900),
  Sample4 = c(0.58, 950),
  row.names = c("Feature1", "Feature2")
)

# Calculate sample distances WITHOUT scaling
dist_unscaled <- dist(t(metabolite_data))

# Calculate sample distances WITH scaling
metabolite_scaled <- t(scale(t(metabolite_data)))
dist_scaled <- dist(t(metabolite_scaled))

# Visualize
par(mfrow = c(1, 2))

# Unscaled: Feature2 dominates!
plot(hclust(dist_unscaled), main = "Unscaled: Feature2 dominates clustering",
     xlab = paste("Sample1-2 close, Sample3-4 close\n",
                  "(only Feature2 matters!)"))

# Scaled: Both metabolites contribute
plot(hclust(dist_scaled), main = "Scaled: Both metabolites contribute equally",
     xlab = "Different clustering pattern")
```

::: {.fragment}
**Key point**: Without scaling, high-variance features (Feature2) completely dominate the distance calculation between samples!

Scaling by row ensures all features contribute equally to sample clustering.
:::

## Proper Heatmap Workflow

::: {.callout-important}
## The Right Approach

1. **Scale your data FIRST** (before creating heatmap)
2. **Calculate dendrograms on scaled data**
3. **Pass pre-calculated dendrograms to heatmap function**
4. **Set `scale = "none"`** in heatmap call

```r
# Proper workflow (using tibbles)
data_scaled <- expr_data %>%
  mutate(across(-Metabolite, ~ scale(.x)[,1]))

data_capped <- data_scaled %>%
  mutate(across(-Metabolite, ~ pmin(pmax(.x, -3), 3)))

# Calculate dendrograms on scaled data
data_mat <- data_capped %>% column_to_rownames("Metabolite") %>% as.matrix()
row_dend <- hclust(dist(data_mat))
col_dend <- hclust(dist(t(data_mat)))

# Plot with pre-computed dendrograms
pheatmap(data_mat,
         cluster_rows = row_dend,
         cluster_cols = col_dend,
         scale = "none")  # Already scaled!
```
:::

## Using massageR::heat.clust

::: {.callout-tip}
## Better Approach: heat.clust

The `massageR` package provides `heat.clust()` which handles scaling and dendrogram calculation correctly in one step!

**Key advantages:**

- Scales data and calculates dendrograms together
- Controls exactly where limits are applied (data and/or dendrograms)
- Returns pre-computed dendrograms
- Works seamlessly with pheatmap
:::

## heat.clust with pheatmap

```{r}
#| label: heat-clust-pheatmap
#| echo: true
#| eval: true
#| fig-width: 10
#| fig-height: 6

library(massageR)

# Convert tibble to matrix for heat.clust
expr_matrix <- expr_data %>%
  column_to_rownames("Metabolite") %>%
  as.matrix()

# Use heat.clust to scale and cluster
z <- heat.clust(expr_matrix,
                scaledim = "row",           # Scale by row
                zlim = c(-3, 3),            # Cap at Â±3
                zlim_select = c("dend", "outdata"),  # Apply to both
                reorder = c("column", "row"),        # Reorder dendrograms
                distfun = function(x) dist(x),
                hclustfun = function(x) hclust(x, method = "complete"),
                scalefun = scale)

# Extract dendrograms and convert to hclust objects
row_dend <- as.hclust(z$Rowv)
col_dend <- as.hclust(z$Colv)

# Use with pheatmap
pheatmap(z$data,
         cluster_rows = row_dend,
         cluster_cols = col_dend,
         scale = "none",
         color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
         breaks = seq(-3, 3, length.out = 101),
         main = "heat.clust + pheatmap: Properly scaled!")
```

## Complete Example: Proper Scaling

```{r}
#| label: proper-scaling-example
#| echo: true
#| eval: true
#| fig-width: 10
#| fig-height: 6

# Step 1: Scale by row (metabolite)
data_scaled <- expr_data %>%
  mutate(across(-Metabolite, ~ scale(.x)[,1]))

# Step 2: Cap extremes at Â±2.5
data_capped <- data_scaled %>%
  mutate(across(-Metabolite, ~ pmin(pmax(.x, -2.5), 2.5)))

# Step 3: Calculate dendrograms on scaled data
data_mat <- data_capped %>% column_to_rownames("Metabolite") %>% as.matrix()
row_dend <- hclust(dist(data_mat))
col_dend <- hclust(dist(t(data_mat)))

# Step 4: Plot with consistent scaling
pheatmap(data_mat,
         cluster_rows = row_dend,
         cluster_cols = col_dend,
         scale = "none",
         color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
         breaks = seq(-2.5, 2.5, length.out = 101),
         main = "Properly scaled: dendrograms match colors!")
```

## Diverging Scales for Centered Data

```{r}
#| label: diverging-scale
#| echo: true
#| eval: true
#| fig-width: 10
#| fig-height: 5

# When zero is meaningful (fold-change, z-scores, etc.)
# Use data_mat from previous chunk (already scaled and capped)
pheatmap(data_mat,
         color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
         breaks = seq(-2.5, 2.5, length.out = 101),
         main = "Diverging scale: zero = white")

# Zero = white, negative = blue, positive = red
```

## When NOT to Cap

::: {.callout-warning}
## Don't cap blindly!

- If outliers are **biologically meaningful** (rare events)
- Small datasets where each value matters
- When you want to highlight extreme values

**Alternative**: Use asterisks or separate panel for outliers
:::

## Comparison: Before and After

```{r}
#| label: heatmap-comparison
#| echo: true
#| eval: true
#| fig-width: 14
#| fig-height: 6

# Side-by-side comparison
library(gridExtra)

# Before: with outlier
p1 <- pheatmap(expr_data %>% column_to_rownames("Metabolite"),
               main = "Uncapped: Pattern lost",
               color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
               silent = TRUE)

# After: outlier capped (data_mat from previous chunk)
p2 <- pheatmap(data_mat,
               main = "Capped at Â±2.5 SD: Patterns visible",
               color = colorRampPalette(rev(brewer.pal(11, "RdBu")))(100),
               breaks = seq(-2.5, 2.5, length.out = 101),
               silent = TRUE)

grid.arrange(p1[[4]], p2[[4]], ncol = 2)
```

## Color Scale Considerations

::: {.callout-important}
## Critical Elements

1. **Always include color scale bar** with numeric labels
2. **Center at meaningful value** (often zero for diverging data)
3. **Label extremes if capped**: "<-2.5" or ">+2.5"
4. **Use appropriate palette**:
   - Diverging for data with meaningful zero (red-white-blue)
   - Sequential for one-directional (viridis)
:::

## Recommendations

::: {.callout-tip}
## Best Practices

1. **Inspect data distribution** before making heatmap
2. **Cap at 2-3 SD** for large datasets with outliers
3. **Use quantiles** (5-95%) for robustness
4. **Always annotate** what you did: "Values capped at Â±3 SD"
5. **Include color scale** with actual values
6. **Scale data BEFORE** passing to heatmap function
7. **Calculate dendrograms** on the same scaled data
8. **Consider `massageR::heat.clust()`** for automatic proper scaling workflow
:::
